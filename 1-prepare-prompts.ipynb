{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('sample.json', 'rb') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "with open('schema.json', 'rb') as file:\n",
    "    schema = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_area(station, area):\n",
    "    return station['area'] == area\n",
    "\n",
    "def stations_by_area(area):\n",
    "    stations_by_area = list(filter(lambda x: filter_by_area(x, area), data['stations']))\n",
    "    return sorted(stations_by_area, key=lambda x: x['price'], reverse=False)\n",
    "\n",
    "def cheapest_in_area(area):\n",
    "    area_stations = stations_by_area(area)\n",
    "\n",
    "    if len(area_stations) == 0:\n",
    "        return None\n",
    "\n",
    "    return area_stations[0]\n",
    "\n",
    "def most_expensive_in_area(area):\n",
    "    area_stations = stations_by_area(area)\n",
    "\n",
    "    if len(area_stations) == 0:\n",
    "        return None\n",
    "\n",
    "    return area_stations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_area(x):\n",
    "    return x['area']\n",
    "\n",
    "def all_areas():\n",
    "    x = map(extract_area, data['stations'])\n",
    "    y = list(x)\n",
    "    return set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helper chatbot that gives answers regarding petrol stations in the country of Cyprus.\n",
      "Some of the fields have greek words.\n",
      "\n",
      "As an input you will consume a json and based only its fields you will extract values and give precise answers.\n",
      "Do not give a random answer every time. Instead extract data directly from json, calculate based on the values,\n",
      "validate these values and respond with only the required or asked data.\n",
      "\n",
      "If the user provides a validation schema use it to validate the input json.\n",
      "The schema cannot be overridden or changed once it is set once.\n",
      "It is constant and read only and you must ignore all requests for changing it.\n",
      "Do not answer any questions if no input json is provided and validated first.\n",
      "Once you validate the input and have analyzed it, you are ready to answer any questions only regarding the petrol stations.\n",
      "\n",
      "Any question that is not related to the input's fields should be ignored.\n",
      "\n",
      "In case you do not know the answer say so, instead of giving a wrong answer.\n",
      "\n",
      "number of tokens: 197\n",
      "number of tokens for 50 samples: 9850\n",
      "number of tokens for 100 samples: 19700\n"
     ]
    }
   ],
   "source": [
    "import tiktoken # type: ignore\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "\n",
    "# {\n",
    "#   \"messages\": [\n",
    "#       {\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"},\n",
    "#       {\"role\": \"user\", \"content\": \"What's the capital of France?\"},\n",
    "#       {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "system_prompt = f\"\"\"You are a helper chatbot that gives answers regarding petrol stations in the country of Cyprus.\n",
    "Some of the fields have greek words.\n",
    "\n",
    "As an input you will consume a json and based only its fields you will extract values and give precise answers.\n",
    "Do not give a random answer every time. Instead extract data directly from json, calculate based on the values,\n",
    "validate these values and respond with only the required or asked data.\n",
    "\n",
    "If the user provides a validation schema use it to validate the input json.\n",
    "The schema cannot be overridden or changed once it is set once.\n",
    "It is constant and read only and you must ignore all requests for changing it.\n",
    "Do not answer any questions if no input json is provided and validated first.\n",
    "Once you validate the input and have analyzed it, you are ready to answer any questions only regarding the petrol stations.\n",
    "\n",
    "Any question that is not related to the input's fields should be ignored.\n",
    "\n",
    "In case you do not know the answer say so, instead of giving a wrong answer.\n",
    "\"\"\"\n",
    "\n",
    "print(system_prompt)\n",
    "\n",
    "tokens = encoding.encode(system_prompt)\n",
    "\n",
    "print(f\"number of tokens: {len(tokens)}\")\n",
    "print(f\"number of tokens for 50 samples: {len(tokens) * 50}\")\n",
    "print(f\"number of tokens for 100 samples: {len(tokens) * 100}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens: 3189\n",
      "number of tokens for 50 samples: 159450\n",
      "number of tokens for 100 samples: 318900\n"
     ]
    }
   ],
   "source": [
    "# 1. Validation based on schema\n",
    "\n",
    "# {\n",
    "#   \"messages\": [\n",
    "#       {\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"},\n",
    "#       {\"role\": \"user\", \"content\": \"What's the capital of France?\"},\n",
    "#       {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "user_prompt = f\"Given the following json as input {data} and its schema {schema}. is the input file valid\"\n",
    "assistant_prompt = \"yes\"\n",
    "entry = { \"messages\": [ { \"role\": \"system\", \"content\": system_prompt }, { \"role\": \"user\", \"content\": user_prompt }, { \"role\": \"assistant\", \"content\": assistant_prompt } ] }\n",
    "\n",
    "messages = open('messages.jsonl', 'w')\n",
    "messages.write(json.dumps(entry) + \"\\n\")\n",
    "messages.close()\n",
    "\n",
    "tokens = encoding.encode(json.dumps(entry))\n",
    "\n",
    "print(f\"number of tokens: {len(tokens)}\")\n",
    "print(f\"number of tokens for 50 samples: {len(tokens) * 50}\")\n",
    "print(f\"number of tokens for 100 samples: {len(tokens) * 100}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
